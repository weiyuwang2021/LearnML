{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ResNet\n",
    "[Deep Residual Learning for Image Recognition](resnet.pdf)\n",
    "\n",
    "ResNet architecture makes use of shortcut connections to solve the vanishing gradient problem. The basic building block of ResNet is a Residual block that is repeated throughout the network.\n",
    "\n",
    "Instead of learning the mapping from x →F(x), the network learns the mapping from x → F(x)+G(x). When the dimension of the input x and output F(x) is the same, the function G(x) = x is an identity function and the shortcut connection is called Identity connection. The identical mapping is learned by zeroing out the weights in the intermediate layer during training since it's easier to zero out the weights than push them to one.\n",
    "\n",
    "For the case when the dimensions of F(x) differ from x (due to stride length>1 in the CONV layers in between), the Projection connection is implemented rather than the Identity connection. The function G(x) changes the dimensions of input x to that of output F(x). Two kinds of mapping were considered in the original paper.\n",
    "\n",
    "- Non-trainable Mapping (Padding): The input x is simply padded with zeros to make the dimension match that of F(x)\n",
    "\n",
    "- Trainable Mapping (Conv Layer): 1x1 Conv layer is used to map x to G(x). It can be seen from the table above that across the network the spatial dimensions are either kept the same or halved, and the depth is either kept the same or doubled and the product of Width and Depth after each conv layer remains the same i.e. 3584. 1x1 conv layers are used to half the spatial dimension and double the depth by using stride length of 2 and multiple of such filters respectively. The number of 1x1 conv layers is equal to the depth of F(x).\n",
    "\n",
    "![image](resnet34.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader,random_split\n",
    "from torchvision import transforms\n",
    "\n",
    "def get_dataloaders(datasetname, batch_size, validation_fraction=0.2, train_transforms=transforms.ToTensor(), test_transforms=transforms.ToTensor()):\n",
    "    # Load train and test datasets\n",
    "    if datasetname == 'CIFAR10':\n",
    "        train_dataset = datasets.CIFAR10(root='data', train=True, transform=train_transforms, download=True)\n",
    "        test_dataset = datasets.CIFAR10(root='data', train=False, transform=test_transforms)\n",
    "    else: # MNIST\n",
    "        train_dataset = datasets.MNIST(root='data', train=True, transform=train_transforms, download=True)\n",
    "        test_dataset = datasets.MNIST(root='data', train=False, transform=test_transforms)\n",
    "\n",
    "    # Split train dataset into train and validation subsets\n",
    "    train_size = int((1 - validation_fraction) * len(train_dataset))\n",
    "    valid_size = len(train_dataset) - train_size\n",
    "    train_subset, val_subset = random_split(train_dataset, [train_size, valid_size])\n",
    "\n",
    "    # Create data loaders for each subset\n",
    "    train_loader = DataLoader(train_subset, batch_size, shuffle=True)\n",
    "    valid_loader = DataLoader(val_subset, batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size, shuffle=True)\n",
    "\n",
    "    return train_loader, valid_loader, test_loader\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed) \n",
    "\n",
    "def compute_accuracy(model, data_loader, device):\n",
    "    with torch.no_grad():    \n",
    "        correct_pred, num_examples = 0, 0\n",
    "        for i, (features, targets) in enumerate(data_loader):\n",
    "\n",
    "            features = features.to(device)\n",
    "            targets = targets.float().to(device)\n",
    "\n",
    "            logits = model(features)\n",
    "            _, predicted_labels = torch.max(logits, 1)\n",
    "\n",
    "            num_examples += targets.size(0)\n",
    "            correct_pred += (predicted_labels == targets).sum()\n",
    "\n",
    "        return correct_pred.float()/num_examples * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SETTINGS\n",
    "BATCH_SIZE = 256\n",
    "NUM_EPOCHS = 50\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "set_seed(123)\n",
    "\n",
    "\n",
    "### CIFAR10 DATASET\n",
    "train_transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((120, 120)),\n",
    "    torchvision.transforms.RandomCrop((110, 110)),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "test_transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((120, 120)),\n",
    "    torchvision.transforms.RandomCrop((110, 110)),\n",
    "    torchvision.transforms.ToTensor(),                \n",
    "    torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "train_loader, valid_loader, test_loader = get_dataloaders('CIFAR10', batch_size=BATCH_SIZE, validation_fraction=0.1, train_transforms=train_transforms, test_transforms=test_transforms)\n",
    "\n",
    "# Checking the dataset\n",
    "for images, labels in train_loader:  \n",
    "    print('Image batch dimensions:', images.shape)\n",
    "    print('Image label dimensions:', labels.shape)\n",
    "    print('Class labels of 10 examples:', labels[:10])\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
