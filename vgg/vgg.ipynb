{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VGG16\n",
    "VGG16 has a total of 138 million parameters. The important point to note here is that all the conv kernels are of size 3x3 and maxpool kernels are of size 2x2 with a stride of two.\n",
    "\n",
    "![image](network.png)\n",
    "\n",
    "The idea behind having fixed size kernels is that all the variable size convolutional kernels used in Alexnet (11x11, 5x5, 3x3) can be replicated by making use of multiple 3x3 kernels as building blocks. The replication is in terms of the receptive field covered by the kernels.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader,random_split\n",
    "from torchvision import transforms\n",
    "\n",
    "def get_dataloaders(datasetname, batch_size, validation_fraction=0.2, train_transforms=transforms.ToTensor(), test_transforms=transforms.ToTensor()):\n",
    "    # Load train and test datasets\n",
    "    if datasetname == 'CIFAR10':\n",
    "        train_dataset = datasets.CIFAR10(root='data', train=True, transform=train_transforms, download=True)\n",
    "        test_dataset = datasets.CIFAR10(root='data', train=False, transform=test_transforms)\n",
    "    else: # MNIST\n",
    "        train_dataset = datasets.MNIST(root='data', train=True, transform=train_transforms, download=True)\n",
    "        test_dataset = datasets.MNIST(root='data', train=False, transform=test_transforms)\n",
    "\n",
    "    # Split train dataset into train and validation subsets\n",
    "    train_size = int((1 - validation_fraction) * len(train_dataset))\n",
    "    valid_size = len(train_dataset) - train_size\n",
    "    train_subset, val_subset = random_split(train_dataset, [train_size, valid_size])\n",
    "\n",
    "    # Create data loaders for each subset\n",
    "    train_loader = DataLoader(train_subset, batch_size, shuffle=True)\n",
    "    valid_loader = DataLoader(val_subset, batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size, shuffle=True)\n",
    "\n",
    "    return train_loader, valid_loader, test_loader\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed) \n",
    "\n",
    "def compute_accuracy(model, data_loader, device):\n",
    "    with torch.no_grad():    \n",
    "        correct_pred, num_examples = 0, 0\n",
    "        for i, (features, targets) in enumerate(data_loader):\n",
    "\n",
    "            features = features.to(device)\n",
    "            targets = targets.float().to(device)\n",
    "\n",
    "            logits = model(features)\n",
    "            _, predicted_labels = torch.max(logits, 1)\n",
    "\n",
    "            num_examples += targets.size(0)\n",
    "            correct_pred += (predicted_labels == targets).sum()\n",
    "\n",
    "        return correct_pred.float()/num_examples * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Image batch dimensions: torch.Size([256, 3, 64, 64])\n",
      "Image label dimensions: torch.Size([256])\n",
      "Class labels of 10 examples: tensor([2, 7, 4, 7, 0, 1, 1, 6, 9, 2])\n"
     ]
    }
   ],
   "source": [
    "### SETTINGS\n",
    "BATCH_SIZE = 256\n",
    "NUM_EPOCHS = 50\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "set_seed(123)\n",
    "\n",
    "\n",
    "### CIFAR10 DATASET\n",
    "train_transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((70, 70)),\n",
    "    torchvision.transforms.RandomCrop((64, 64)),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "test_transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((70, 70)),\n",
    "    torchvision.transforms.RandomCrop((64, 64)),\n",
    "    torchvision.transforms.ToTensor(),                \n",
    "    torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "train_loader, valid_loader, test_loader = get_dataloaders('CIFAR10', batch_size=BATCH_SIZE, validation_fraction=0.1, train_transforms=train_transforms, test_transforms=test_transforms)\n",
    "\n",
    "# Checking the dataset\n",
    "for images, labels in train_loader:  \n",
    "    print('Image batch dimensions:', images.shape)\n",
    "    print('Image label dimensions:', labels.shape)\n",
    "    print('Class labels of 10 examples:', labels[:10])\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### VGG Network\n",
    "![image](parameters.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block2C(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.block = torch.nn.Sequential(\n",
    "                torch.nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, stride=1, padding=1),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=3, stride=1, padding=1),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "    \n",
    "class Block3C(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.block = torch.nn.Sequential(\n",
    "                torch.nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, stride=1, padding=1),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=3, stride=1, padding=1),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=3, stride=1, padding=1),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "    \n",
    "class VGG16(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.block_1 = Block2C(3, 64)\n",
    "        self.block_2 = Block2C(64, 128)\n",
    "        self.block_3 = Block3C(128,256)\n",
    "        self.block_4 = Block3C(256, 512)\n",
    "        self.block_5 = Block3C(512, 512)\n",
    "        height,width = 3, 3\n",
    "        self.avgpool = torch.nn.AdaptiveAvgPool2d((height, width))\n",
    "        self.classifier = torch.nn.Sequential(\n",
    "            torch.nn.Linear(512*height*height, 4096),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.Dropout(p=0.5),\n",
    "            torch.nn.Linear(4096, 4096),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.Dropout(p=0.5),\n",
    "            torch.nn.Linear(4096, num_classes))\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, torch.torch.nn.Conv2d) or isinstance(m, torch.torch.nn.Linear):\n",
    "                torch.nn.init.kaiming_uniform_(m.weight, mode='fan_in', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    m.bias.detach().zero_()\n",
    "        \n",
    "    def forward(self, x):                       #[n, 3, 64, 64]\n",
    "\n",
    "        x = self.block_1(x)                     #[n, 64, 32, 32]\n",
    "        x = self.block_2(x)                     #[n, 128, 16, 16]\n",
    "        x = self.block_3(x)                     #[n, 256, 8, 8]\n",
    "        x = self.block_4(x)                     #[n, 512, 4, 4]\n",
    "        x = self.block_5(x)                     #[n, 512, 2, 2]\n",
    "        x = self.avgpool(x)                     #[n, 512, 3, 3]\n",
    "        x = x.view(x.size(0), -1) # flatten     #[n, 4608]\n",
    "        \n",
    "        logits = self.classifier(x)\n",
    "\n",
    "        return logits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1+cpu\n",
      "None\n",
      "Epoch: 001/050 Batch 0000/0176 | Loss: 2.3031\n"
     ]
    }
   ],
   "source": [
    "#check if cuda available\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "\n",
    "import time\n",
    "model = VGG16(num_classes=10)\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), momentum=0.9, lr=0.1)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, mode='max', verbose=True)\n",
    "\n",
    "minibatch_loss_list, train_acc_list, valid_acc_list = [], [], []\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "\n",
    "    model.train()\n",
    "    for batch_idx, (features, targets) in enumerate(train_loader):\n",
    "\n",
    "        features = features.to(DEVICE)\n",
    "        targets = targets.to(DEVICE)\n",
    "\n",
    "        # ## FORWARD AND BACK PROP\n",
    "        logits = model(features)\n",
    "        loss = torch.nn.functional.cross_entropy(logits, targets)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # ## LOGGING\n",
    "        minibatch_loss_list.append(loss.item())\n",
    "        if not batch_idx % 100:\n",
    "            print(f'Epoch: {epoch+1:03d}/{NUM_EPOCHS:03d} Batch {batch_idx:04d}/{len(train_loader):04d} | Loss: {loss:.4f}')\n",
    "\n",
    "    model.eval()\n",
    "    train_acc = compute_accuracy(model, train_loader, device=DEVICE)\n",
    "    valid_acc = compute_accuracy(model, valid_loader, device=DEVICE)\n",
    "    print(f'Epoch: {epoch+1:03d}/{NUM_EPOCHS:03d} | Train: {train_acc :.2f}% | Validation: {valid_acc :.2f}%')\n",
    "    train_acc_list.append(train_acc.item())\n",
    "    valid_acc_list.append(valid_acc.item())\n",
    "    \n",
    "    scheduler.step(valid_acc_list[-1])\n",
    "\n",
    "elapsed = (time.time() - start_time)/60\n",
    "print(f'Time elapsed: {elapsed:.2f} min')\n",
    "\n",
    "test_acc = compute_accuracy(model, test_loader, device=DEVICE)\n",
    "print(f'Test accuracy {test_acc :.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
